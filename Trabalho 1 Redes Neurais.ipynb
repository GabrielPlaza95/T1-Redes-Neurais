{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDNWorbh4IqQU2Y3jmzjWW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Importação dos dados e arquivos da tarefa\n",
        "\n",
        "!git clone https://github.com/GabrielPlaza95/T1-Redes-Neurais.git\n",
        "\n",
        "%cd T1-Redes-Neurais"
      ],
      "metadata": {
        "id": "XWxS5QIgN4AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importação de bibliotecas e definições auxiliares\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from itertools import product as cartesian_product\n",
        "\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics, 'b--')\n",
        "    plt.plot(epochs, val_metrics, 'r-')\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "\n",
        "def describe_model(model, model_hyper_params):\n",
        "    model.summary()\n",
        "\n",
        "    hp = model_hyper_params[model.name]\n",
        "    print()\n",
        "    print(\"Neurônios na camada escondida:\", hp[\"neurons\"])\n",
        "    print(\"Registros por etapa:\", hp[\"batch_size\"])\n",
        "    print(\"Função de ativação da camada escondida:\", hp[\"activation\"])\n",
        "    print(\"Otimizador:\", hp[\"optimizer\"])\n",
        "\n",
        "def print_results(y_pred, y_test):\n",
        "    print(\"Resultados de Teste:\\n\")\n",
        "\n",
        "    #Decodificação das saídas\n",
        "    y_pred_dec = np.argmax(y_pred, axis = 1)\n",
        "    y_test_dec = np.argmax(y_test, axis = 1)\n",
        "\n",
        "    cm = confusion_matrix(y_test_dec, y_pred_dec)\n",
        "    cr = classification_report(y_test_dec, y_pred_dec)\n",
        "    print(cr)\n",
        "    print(\"Matriz de Confusão:\\n\")\n",
        "    print(np.matrix(cm))\n"
      ],
      "metadata": {
        "id": "JXe03oJHz0uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leitura dos dados\n",
        "dataset = pd.read_csv('data/cell_train.csv') #You need to change #directory accordingly\n",
        "\n",
        "#Visualização dos Dados\n",
        "print(\"Amostra dos dados:\")\n",
        "print(dataset.head(5))\n",
        "\n",
        "#sns.pairplot(dataset, hue=\"price_range\")"
      ],
      "metadata": {
        "id": "wRk66Robcl8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conversão para array\n",
        "atributos = 20\n",
        "X = dataset.iloc[:, :atributos].values\n",
        "y = dataset.iloc[:, atributos:atributos + 1].values\n",
        "\n",
        "#Normalização\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "#Categorização one-hot da saída\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,test_size = 0.20, random_state = 19)\n",
        "\n",
        "sm = SMOTE(random_state = 19)\n",
        "X_res_train, y_res_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "X_train = X_res_train\n",
        "y_train = y_res_train\n",
        "\n",
        "#Hiperparâmetros a serem avaliados\n",
        "\n",
        "num_neurons = (200, 100)\n",
        "batch_sizes = (256, 128, 64)\n",
        "activations = (\"relu\", \"tanh\")\n",
        "optimizers = (\"sgd\", \"adam\")\n",
        "\n",
        "hyper_params = cartesian_product(num_neurons, batch_sizes, activations, optimizers)\n",
        "model_hyper_params = {}\n",
        "\n",
        "max_val_acc = 0\n",
        "\n",
        "for (i, (neurons, batch_size, activation, optimizer)) in enumerate(hyper_params):\n",
        "    model_name = f\"Modelo_{i+1}\"\n",
        "    model_hyper_params[model_name] = {\n",
        "        \"neurons\": neurons,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"activation\": activation,\n",
        "        \"optimizer\": optimizer\n",
        "    }\n",
        "    model = Sequential(name = model_name)\n",
        "    model.add(Dense(neurons, activation = activation, input_shape = (atributos, ), name = \"Escondida\"))\n",
        "    model.add(Dense(4, activation = 'softmax', name = \"Saida\"))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer = optimizer,\n",
        "        loss = 'categorical_crossentropy', \n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    \n",
        "    ces = EarlyStopping(\n",
        "        monitor = 'val_accuracy',\n",
        "        patience = 10,\n",
        "        min_delta = 0.001,\n",
        "        mode = 'max',\n",
        "        restore_best_weights = True,\n",
        "        start_from_epoch = 50\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        batch_size = batch_size,\n",
        "        epochs = 500,\n",
        "        validation_split = 0.2,\n",
        "        verbose = 0,\n",
        "        callbacks = [ces]\n",
        "    )\n",
        "    \n",
        "    print('\\n########################################################################\\n')\n",
        "    describe_model(model, model_hyper_params)\n",
        "\n",
        "    plot_metric(history, 'loss')\n",
        "    plot_metric(history, 'accuracy')\n",
        "\n",
        "    #Gravando modelo de maior acurácia na validação\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    print(\"Acurácia de validação:\", val_acc)\n",
        "\n",
        "    if (val_acc > max_val_acc):\n",
        "        max_val_acc = val_acc\n",
        "        model.save('best_model.h5')\n",
        "\n",
        "    y_pred = model.predict(X_test, verbose = 0)\n",
        "    print_results(y_pred, y_test)"
      ],
      "metadata": {
        "id": "whiE3OGOPz_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhor modelo salvo\n",
        "print('Melhor Modelo:\\n')\n",
        "\n",
        "saved_model = load_model('best_model.h5')\n",
        "describe_model(saved_model, model_hyper_params)\n",
        "\n",
        "y_pred = saved_model.predict(X_test, verbose = 0)\n",
        "print_results(y_pred, y_test)\n",
        "\n",
        "#Reset\n",
        "model_hyper_params = {}\n",
        "clear_session()"
      ],
      "metadata": {
        "id": "783GpuKA_k1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}